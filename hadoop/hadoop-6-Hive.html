<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Hive | JavaChen Wiki</title>
    <meta name="description" content="JavaChen Wiki">
    <link rel="icon" href="/wiki/img/logo.ico">
  <meta http-quiv="pragma" cotent="no-cache">
  <meta http-quiv="pragma" cotent="no-cache,must-revalidate">
  <meta http-quiv="expires" cotent="0">
    
    <link rel="preload" href="/wiki/assets/css/0.styles.bdf32acf.css" as="style"><link rel="preload" href="/wiki/assets/js/app.dd178f5a.js" as="script"><link rel="preload" href="/wiki/assets/js/2.9f273a62.js" as="script"><link rel="preload" href="/wiki/assets/js/25.306828f5.js" as="script"><link rel="prefetch" href="/wiki/assets/js/10.e389070d.js"><link rel="prefetch" href="/wiki/assets/js/11.19e9f97f.js"><link rel="prefetch" href="/wiki/assets/js/12.f95e0459.js"><link rel="prefetch" href="/wiki/assets/js/13.127730fd.js"><link rel="prefetch" href="/wiki/assets/js/14.34eed2f7.js"><link rel="prefetch" href="/wiki/assets/js/15.a8cf4000.js"><link rel="prefetch" href="/wiki/assets/js/16.6346731c.js"><link rel="prefetch" href="/wiki/assets/js/17.143af375.js"><link rel="prefetch" href="/wiki/assets/js/18.7d95703a.js"><link rel="prefetch" href="/wiki/assets/js/19.8726bd0b.js"><link rel="prefetch" href="/wiki/assets/js/20.2914a04f.js"><link rel="prefetch" href="/wiki/assets/js/21.ebd751e0.js"><link rel="prefetch" href="/wiki/assets/js/22.f6801be0.js"><link rel="prefetch" href="/wiki/assets/js/23.87ecfe73.js"><link rel="prefetch" href="/wiki/assets/js/24.cabcaf93.js"><link rel="prefetch" href="/wiki/assets/js/26.59450304.js"><link rel="prefetch" href="/wiki/assets/js/27.44fddb85.js"><link rel="prefetch" href="/wiki/assets/js/28.4e15bea1.js"><link rel="prefetch" href="/wiki/assets/js/29.bed7cbfd.js"><link rel="prefetch" href="/wiki/assets/js/3.28138f41.js"><link rel="prefetch" href="/wiki/assets/js/30.36a67cca.js"><link rel="prefetch" href="/wiki/assets/js/31.dde8666e.js"><link rel="prefetch" href="/wiki/assets/js/32.148ea73a.js"><link rel="prefetch" href="/wiki/assets/js/33.61c937cc.js"><link rel="prefetch" href="/wiki/assets/js/34.eb7c4b0c.js"><link rel="prefetch" href="/wiki/assets/js/35.abb4ce3d.js"><link rel="prefetch" href="/wiki/assets/js/36.f03d0378.js"><link rel="prefetch" href="/wiki/assets/js/37.84491176.js"><link rel="prefetch" href="/wiki/assets/js/38.2a06b872.js"><link rel="prefetch" href="/wiki/assets/js/39.63965d3b.js"><link rel="prefetch" href="/wiki/assets/js/4.c0af9872.js"><link rel="prefetch" href="/wiki/assets/js/40.bf2e354a.js"><link rel="prefetch" href="/wiki/assets/js/41.bed53451.js"><link rel="prefetch" href="/wiki/assets/js/42.34d4f2f5.js"><link rel="prefetch" href="/wiki/assets/js/43.867c0e23.js"><link rel="prefetch" href="/wiki/assets/js/44.0201a314.js"><link rel="prefetch" href="/wiki/assets/js/45.d6f1a311.js"><link rel="prefetch" href="/wiki/assets/js/46.419d44e4.js"><link rel="prefetch" href="/wiki/assets/js/47.a3f8b595.js"><link rel="prefetch" href="/wiki/assets/js/48.574cc219.js"><link rel="prefetch" href="/wiki/assets/js/49.224dd6c4.js"><link rel="prefetch" href="/wiki/assets/js/5.c521f8b1.js"><link rel="prefetch" href="/wiki/assets/js/50.c8825040.js"><link rel="prefetch" href="/wiki/assets/js/51.2dab614a.js"><link rel="prefetch" href="/wiki/assets/js/52.8382a180.js"><link rel="prefetch" href="/wiki/assets/js/53.bfab18a9.js"><link rel="prefetch" href="/wiki/assets/js/54.87a1d37c.js"><link rel="prefetch" href="/wiki/assets/js/55.5f207671.js"><link rel="prefetch" href="/wiki/assets/js/56.f0e8e082.js"><link rel="prefetch" href="/wiki/assets/js/57.c868e5c9.js"><link rel="prefetch" href="/wiki/assets/js/6.6a737c5b.js"><link rel="prefetch" href="/wiki/assets/js/7.48bba6b4.js"><link rel="prefetch" href="/wiki/assets/js/8.26532964.js"><link rel="prefetch" href="/wiki/assets/js/9.3c4a4032.js">
    <link rel="stylesheet" href="/wiki/assets/css/0.styles.bdf32acf.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/wiki/" class="home-link router-link-active"><!----> <span class="site-name">JavaChen Wiki</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/wiki/" class="nav-link">主页</a></div><div class="nav-item"><a href="/wiki/docker/" class="nav-link">Docker</a></div><div class="nav-item"><a href="/wiki/elasticsearch/" class="nav-link">Elasticsearch</a></div><div class="nav-item"><a href="/wiki/hadoop/" class="nav-link router-link-active">Hadoop</a></div><div class="nav-item"><a href="/wiki/interview/" class="nav-link">Interview</a></div><div class="nav-item"><a href="/wiki/rabbitMQ/" class="nav-link">RabbitMQ</a></div><div class="nav-item"><a href="/wiki/redis/" class="nav-link">Redis</a></div><div class="nav-item"><a href="/wiki/spring-cloud-cshop/" class="nav-link">Spring-cloud-cshop</a></div><div class="nav-item"><a href="/wiki/about.html" class="nav-link">关于</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/wiki/" class="nav-link">主页</a></div><div class="nav-item"><a href="/wiki/docker/" class="nav-link">Docker</a></div><div class="nav-item"><a href="/wiki/elasticsearch/" class="nav-link">Elasticsearch</a></div><div class="nav-item"><a href="/wiki/hadoop/" class="nav-link router-link-active">Hadoop</a></div><div class="nav-item"><a href="/wiki/interview/" class="nav-link">Interview</a></div><div class="nav-item"><a href="/wiki/rabbitMQ/" class="nav-link">RabbitMQ</a></div><div class="nav-item"><a href="/wiki/redis/" class="nav-link">Redis</a></div><div class="nav-item"><a href="/wiki/spring-cloud-cshop/" class="nav-link">Spring-cloud-cshop</a></div><div class="nav-item"><a href="/wiki/about.html" class="nav-link">关于</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Hadoop</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/wiki/hadoop/" class="sidebar-link">大数据概论</a></li><li><a href="/wiki/hadoop/hadoop-2-Hadoop概述.html" class="sidebar-link">Hadoop</a></li><li><a href="/wiki/hadoop/hadoop-3-hdfs.html" class="sidebar-link">HDFS</a></li><li><a href="/wiki/hadoop/hadoop-4-MapReduce.html" class="sidebar-link">MapReduce</a></li><li><a href="/wiki/hadoop/hadoop-5-Yarn.html" class="sidebar-link">Yarn</a></li><li><a href="/wiki/hadoop/hadoop-6-Hive.html" class="active sidebar-link">Hive</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/wiki/hadoop/hadoop-6-Hive.html#简介" class="sidebar-link">简介</a></li><li class="sidebar-sub-header"><a href="/wiki/hadoop/hadoop-6-Hive.html#优缺点" class="sidebar-link">优缺点</a></li><li class="sidebar-sub-header"><a href="/wiki/hadoop/hadoop-6-Hive.html#hive架构原理" class="sidebar-link">hive架构原理</a></li><li class="sidebar-sub-header"><a href="/wiki/hadoop/hadoop-6-Hive.html#和数据库比较" class="sidebar-link">和数据库比较</a></li><li class="sidebar-sub-header"><a href="/wiki/hadoop/hadoop-6-Hive.html#分桶及抽样查询" class="sidebar-link">分桶及抽样查询</a></li><li class="sidebar-sub-header"><a href="/wiki/hadoop/hadoop-6-Hive.html#压缩和存储" class="sidebar-link">压缩和存储</a></li><li class="sidebar-sub-header"><a href="/wiki/hadoop/hadoop-6-Hive.html#hive优化" class="sidebar-link">hive优化</a></li></ul></li><li><a href="/wiki/hadoop/hadoop-7-Kafka.html" class="sidebar-link">Kafka</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="hive"><a href="#hive" aria-hidden="true" class="header-anchor">#</a> Hive</h1> <h2 id="简介"><a href="#简介" aria-hidden="true" class="header-anchor">#</a> 简介</h2> <p>Hive由Facebook开源用于解决海量结构化日志的数据统计。Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类Sql查询的功能。</p> <p>hive本质是将HQL转化为MapReduce的程序</p> <p>hive处理的数据存储在HDFS</p> <p>hive分析数据低层的实现是MapReduce</p> <p>执行程序运行在YARN上</p> <h2 id="优缺点"><a href="#优缺点" aria-hidden="true" class="header-anchor">#</a> 优缺点</h2> <p>1.优点：</p> <ul><li>操作接口采用类sql语法，提供快速开发的能力</li> <li>避免去写MapReduce，减少开发人员的学习成本。</li> <li>Hive的执行延迟比较高，因此Hive常用于数据分析，对实时性要求不高的场合。</li> <li>Hive优势在于处理大数据，对于处理小数据没有优势，应为Hive的数据延迟比较高。</li> <li>Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数</li></ul> <p>2.缺点：</p> <ul><li>Hive的HQL表达能力有限
<ul><li>迭代式算法无法表达</li> <li>数据挖掘方面不擅长</li></ul></li> <li>hive的效率较低
<ul><li>Hive自动生成MapReduce作业，通常情况下不够智能化</li> <li>Hive调优比较困难，粒度较粗</li></ul></li></ul> <h2 id="hive架构原理"><a href="#hive架构原理" aria-hidden="true" class="header-anchor">#</a> hive架构原理</h2> <p><img src="http://ww2.sinaimg.cn/large/006tNc79gy1g5abelvnmsj30nk0kiacw.jpg" alt="img"></p> <p>Hive通过给用户提供的一系列交互接口，接收到用户的指令（SQL），使用注解的Drive，结合元数据（MetaStore），将这些指令翻译成MapReduce，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口。</p> <p>1.用户接口：Client</p> <p>CLI（hive shell）、JDBC/ODBC（java访问Hive）、WEBUI（浏览器访问hive）</p> <p>2.元数据：Metastore</p> <p>元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；</p> <p>默认存储在自带的derby数据库中，推荐使用Mysql存储Metastore</p> <p>3.Hadoop</p> <p>使用HDFS进行存储，使用MapReduce进行计算。</p> <p>4.驱动器：Driver</p> <p>解析器（SQL parser）：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方的工具完成。</p> <p>编译器（Physical Plan）：将AST编译生成逻辑执行计划。</p> <p>优化器（QUery Optimizer）：对逻辑执行计划进行优化</p> <h2 id="和数据库比较"><a href="#和数据库比较" aria-hidden="true" class="header-anchor">#</a> 和数据库比较</h2> <p>Hive采用了类似Sql的查询语言HQL（Hive Query Language），因此很容易将Hive理解为数据库。从结构上来看，Hive和数据库除了拥有类似的查询语言，再无类似之处。数据库可以用于Online的应用，但是Hive是为数据仓库而设计的，清楚这一点，有助于从应用角度理解Hive的特效</p> <p>1.查询语言</p> <p>Sql被广泛的应用在数据仓库中，因此，专门针对hive的特性设计了类sql的查询语言HQl。熟悉Sql的开发者可以很方便的使用Hive进行开发。</p> <p>2.数据存储位置</p> <p>Hive是建立在Hadoop之上的，所有hive的数据都是存储在HDFS中，而数据库则可以将数据保存在块设备或者本地文件系统中。</p> <p>3.数据更新</p> <p>由于Hive是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此，Hive中不支持对数据的改写和添加，所有的数据都是加载的时候确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以修改数据。</p> <p>4.索引</p> <p>Hive在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些key简历索引，Hive要访问数据中满足条件的特定值式，需要暴力扫描整个数据，因此访问延迟较高。有与MapReduce的引入，Hive可以并行访问数据，因此即使没有索引，对于大数据量的访问，Hive仍然可以体现出优势。数据库中，通常会针对一个或者几个列建立索引，因此对于少了的特定数据的访问，数据库可以有很高的效率，较低的延迟。数据的访问延迟修改较高，决定了Hive不适合在线数据查询</p> <p>5.执行</p> <p>Hive中大多数查询的执行是通过Hadoop提供的MapReduce来实现的。而数据库通常有自己的执行引擎</p> <p>6.执行延迟</p> <p>Hive在查询数据的过程，由于没有索引，需要扫描整个表，因此延迟较高。另外一个导致Hive执行延迟高的因素是MapReduce框架。由于MapReduce本身具有较高的延迟，因此在利用MapReduce执行Hive查询时，也会有较高的延迟。相对的，数据库的执行延迟较低。当热，这个低是有条件的，数据规模要较小，当数据规模大到超过数据库的处理能力的时候，Hive的并行计算显然能体现出优势。</p> <p>7.可扩展性</p> <p>由于Hive是建立在Hadoop之上的，因此Hive的可扩展性是和Hadoop的可扩展性是一致的，而数据库由于ACID语义的严格限制，扩展性非常有限。（2009年的Yahoo的hadoop集群已经达到4000台，而同期的Oracle数据库理论扩展上线只有100台左右）</p> <p>8.数据规模</p> <p>Hive利用MapReduce进行并行计算，可以支持很大规模的数据，而普通的数据库可以支持的数据规模就要小很多</p> <h2 id="分桶及抽样查询"><a href="#分桶及抽样查询" aria-hidden="true" class="header-anchor">#</a> 分桶及抽样查询</h2> <p>1.分桶表数据存储</p> <p>分区针对的是数据存储路径（HDFS中表现出来的便是文件夹），分桶针对的是数据文件。分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区，特别是当数据要确定合适的划分大小的时候，分区便不再合适。分桶是将数据集分解成更容易管理的若干部分的技术。</p> <p>2.先创建分桶表，通过直接导入数据的方式插入数据</p> <p>创建分桶表</p> <p>create table stu_buck(id int,name string)
clustered by(id)
into 4 buckets
row format delimited fields terminated by '\t';
查看表结构</p> <p>desc formatted stu_buck;</p> <p>红色标记出来的地方便是分桶的数量</p> <p>将分桶功能开启（默认为false）</p> <p>set hive.enforce.bucketing = true;
设置reduce个数（设置成不限制）</p> <p>set mapreduce.job.reduces=-1;
通过文件导入数据</p> <p>load data local inpath '/opt/student.txt' into table stu_buck;
通过子查询方式导入数据（这里的时候抛出一个异常，重启服务器之后异常消失）</p> <p>insert into table stu_buck select id,name from stu;</p> <p>3.分桶采样查询</p> <p>​    对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。Hive可以通过对表进行抽样来满足这个需求。</p> <p>select * from stu_buck TABLESAMPLE(bucket 1 out of 4 on id);
tablesample便是抽样语句，语法：</p> <p>TABLESAMPLE(BUCKET x OUT OF y);
y必须是table总bucket数的倍数或者是因子。hive会根据y的大小，决定抽样的比例。例如：table总共被分了4份，当y=2时，抽取（4/2=）2个bucket的数据，当y=8时，抽取（4/8=）1/2个bucket的数据。</p> <p>x则表示从哪个bucket开始抽样。例如：table总bucket数为4，tablesample（bucket4 out of 4），表示总共抽取（4/4=）1个bucket的数据，抽取第4个bucket的数据。</p> <p>这里x的值必须小于等于y的值，否则会抛出异常。</p> <p>FAILED:SemanticException[Error 10061]:Numerator should not be bigger than denonminator in sample clause for table stu_buck
hive还提供了另外一种按照百分百进行抽样的方式，这种事基于行数的，按照输入路径下的数据块百分比进行的采样。</p> <p>select * from stu tablesample(0.1 percent);
这种抽样方式不一定适合于所有的文件格式。另外，这种抽样的最小抽样单元是一个HDFS数据。因此，如果这个表数据大小小于普通的的块大小（128m）的话，那么将会返回所有行。</p> <h2 id="压缩和存储"><a href="#压缩和存储" aria-hidden="true" class="header-anchor">#</a> 压缩和存储</h2> <h3 id="压缩"><a href="#压缩" aria-hidden="true" class="header-anchor">#</a> 压缩</h3> <p>1.设置hadoop的压缩配置</p> <p>参照之前的博客：https://blog.csdn.net/qq_34886352/article/details/82689965</p> <p>2.开启Map输入阶段的压缩，可以减少job中map和Reduce task间数据传输量。</p> <p>​    1.开启hive中间传输数据压缩功能</p> <p>set hive.exec.compress.intermediate=true;
2.开启mapreduce中map输出压缩功能</p> <p>set mapreduce.map.output.compress=true;
3.设置mapreduce中map输出数据的压缩方式</p> <p>set mapreduce.map.outputcompress.codec={压缩格式参照上面博客的格式}
3.开启reduce输出阶段压缩</p> <p>​    当Hive将输出写入到表中时，输出内容同样可以进行压缩。属性hive.exec.compress.output控制这个功能，可以通过在查询语句中或者执行脚本中设置这个值为true。</p> <p>​    1.开启hive最终输出数据压缩功能</p> <p>set hive.exec.compress.output=true;
2.开启mapreduce最终输出数据压缩</p> <p>set mapreduce.output.fileoutputformat.compress=true;
3.设置mapreduce最终数据输出压缩方式</p> <p>set mapreduce.output.fileoutputformat.compress.codec={压缩格式参照上面博客的格式}
4.设置mapreduce最终数据输出压缩为块压缩</p> <p>set mapreduce.output.fileoutputformat.compress.type=BLOCK;</p> <h3 id="存储"><a href="#存储" aria-hidden="true" class="header-anchor">#</a> 存储</h3> <p>1.文件存储格式</p> <p>hive支持的文件存储的格式主要有：TEXTFILE、SEQUENCEFILE、ORC、PARQUET。</p> <p>2.列式存储和行式存储</p> <p><img src="http://ww2.sinaimg.cn/large/006tNc79gy1g5aaam90p1j32180qp1kx.jpg" alt="img"></p> <p>行存储的特点：查询满足条件的一整行数据的时候，列存储则需要去每个聚集的字段找到对应的每个列，行存储只需要找到其中的一个值，其余的值就在相邻的地方，所以此时行存储查询的速度更快。</p> <p>​    列存储的特点：应为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读的数据量；每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的压缩算法。</p> <p>​    TEXTFILE和SEQUENCEFILE的存储格式都是基于行存储的。</p> <p>​    ORC和PARQUET是基于列式存储的</p> <p>3.TextFile格式</p> <p>​    默认格式，数据不做压缩，磁盘开销大，数据解析开销大。可集合Gzip和Bzip2使用，但使用这种方式，hive不会对数据进行切分，从而无法对数据进行并行操作。</p> <p>4.Orc格式</p> <p>​    ORC(Optimized Row Columnar)是hive0.11版里引入的新的存储格式。</p> <p>​    可以看到每个Orc文件由1个或多个Stripe组成，每个Stripe250M大小，这个Stripe实际相对于RowGroup概念，不过大小由4MB-&gt;250MB，这样能提升顺序读取的吞吐率。</p> <p>每个Stripe里有三部分组成，分别是Index Data，RowData，Stripe Footer：</p> <p><img src="http://ww4.sinaimg.cn/large/006tNc79gy1g5aaake8ayj30u015hnii.jpg" alt="img"></p> <p>Index Data：一个轻量级的index，默认是每隔1W行做一个索引。这里做的索引应该只是记录某行的的个字段的RowData中offset。</p> <p>​    Row Data：存的是具体的数据，先取部分行，然后对这些行按列进行存储。对每个列进行了编码，分成对多个Stream来存储。</p> <p>​    StripeFooter：存的是各个Steam的类型，长度等信息。</p> <p>​    每个文件有一个FileFooter，这个在里面存的是每个Stripe的行数，每个Column的数据类型信息等；每个文件的尾部是一个PostScript，这里面记录了整个文件的压缩类型以及FileFooter的长度信息等。在读取文件时，会seek到文件尾部读PostScript。从里面解析到FileFooter长度，在读到FileFooter，从里面解析到各个Stripe信息，再读各个Stripe，即从后往前读。</p> <p>5.Parquet格式</p> <p>​    parquet是面向分析型业务的列式存储格式，由Twitter和Cloudera合作开发，2015年5月从Apache的卵化器里毕业未Apache顶级项目。</p> <p>​    Parquet文件是以二进制方式存储的，所有是不可以直接读取的，文件中包括该文件的数据和元数据，因此Parquet格式文件是自解析的。</p> <p>​    通常情况下，在存储Parquet数据的时候会按照Block大小设置行组的大小，由于一般情况下每个Mapper任务处理数据的最小单位是一个Block，这样可以把每一个行组由一个mapper任务处理，增大任务执行并行度。Parquet文件格式如下</p> <p><img src="http://ww2.sinaimg.cn/large/006tNc79gy1g5aaahh1j3j313k0u0123.jpg" alt="img"></p> <p>个文件中可以存储多个行组，文件的首位都是该文件MagicCode，用于校验它是否是一个Parquet文件，Footer length记录了文件元数据的大小，通过该值和文件长度可以计算出元数据的偏移量，文件的元数据中包括每一个行组的元数据信息，和该文件存储数据的Schema信息。除了文件中每一个行组的元数据，每一夜的开始都会存储该页的元数据，在Parquet中，有三种类型的页：数据页、字典页和索引页。数据页用于存储当前行组中该列的值，字典页存储该列值的编码字典，每一个列块中最多包含一个字典页，索引页用来存储当前行组下该列的索引。</p> <p>6.主流文件存储格式对比</p> <p>存储文件压缩比：ORC&gt;Parquet&gt;TextFile</p> <p>存储文件的速度对比：ORC&gt;TextFile&gt;Parquet（实际上三者几乎一样）</p> <h2 id="hive优化"><a href="#hive优化" aria-hidden="true" class="header-anchor">#</a> hive优化</h2> <h3 id="fetch抓取"><a href="#fetch抓取" aria-hidden="true" class="header-anchor">#</a> Fetch抓取</h3> <p>​    Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如，select * from employees;在这种情况下，Hive可以简单读取employee对应的存储目录下的文件，然后输出查询结果到控制台。</p> <p>​    在hive-default.xml.template文件中hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为move以后，在全局查询、字段查找、limti查询查找等都不是MapReduce。</p> <div class="language- extra-class"><pre class="language-text"><code>&lt;property&gt;
    &lt;name&gt;hive.fetch.task.conversion&lt;/name&gt;
    &lt;value&gt;more&lt;/value&gt;
&lt;/property&gt;
</code></pre></div><h3 id="本地模式"><a href="#本地模式" aria-hidden="true" class="header-anchor">#</a> 本地模式</h3> <p>​    大多数的HadoopJob是需要Hadoop提供的完整的可扩展性来处理大数据集，不过有时Hive的输入量非常小的。这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多得多。对于大多数这种情况，hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</p> <p>​    用户可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。</p> <p>开启本地mr</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.exec.mode.local.auto=true;
</code></pre></div><p>设置local.mr的最大输入数据量，当输入数据量小于这个值时采用local.rm的方式，默认为134217728，即128M</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.exec.mode.local.auto.inputbytes.max=500000000;
</code></pre></div><p>设置local.mr的最大输入文件个数，当输入文件个数小于这个值时采用local.mr方式，默认为4</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.exec.mode.local.auto.input.files.max=10;
</code></pre></div><h3 id="小表、大表join"><a href="#小表、大表join" aria-hidden="true" class="header-anchor">#</a> 小表、大表Join</h3> <p>​    将key相对分散，且数据量小的表放在join的左边，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用Group让小的维度表（1000条以下的记录条数）先进内存。在map端完成Reduce。</p> <p>​    实际上新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化，已经没什么区别。</p> <p>可以通过参数关闭掉这个优化</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.auto.convert.join = false;
</code></pre></div><h3 id="大表join大表"><a href="#大表join大表" aria-hidden="true" class="header-anchor">#</a> 大表JOIN大表</h3> <p>1.空Key过滤</p> <p>​    有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤，过滤掉key对应的字段为空。</p> <p>​    1.配置历史服务器</p> <p>​    配置mapred-site.xml</p> <div class="language- extra-class"><pre class="language-text"><code>&lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
    &lt;value&gt;{服务器地址}:10020&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
&lt;/property&gt;
</code></pre></div><p>​        2.关闭MapJoin功能</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.auto.convert.join = flase;
</code></pre></div><p>​        3.执行不过滤空id的语句</p> <div class="language- extra-class"><pre class="language-text"><code>insert overwrite table jointable
selet n.* from nullidtable n left ori o on n.id = o.id;
</code></pre></div><p>​        4.执行过滤空id的语句</p> <div class="language- extra-class"><pre class="language-text"><code>insert overwrite table jointable
select n.* from(select * from nullidtable where id is not null)n left join ori on n.id = o.id
</code></pre></div><p>2.空key转换</p> <p>​    有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋值一个随机的值， 使得数据随机均匀放分不痛的reducer上。</p> <p>​    1.设置5个reduce个数</p> <div class="language- extra-class"><pre class="language-text"><code>set mapreduce.job.reduces = 5;
</code></pre></div><p>​        2.两种表join</p> <div class="language- extra-class"><pre class="language-text"><code>insert overwrite table jointable
select n.* from nullidtable n full join ori o on
case when n.id is null then concat(&quot;hive&quot;,rand()) else n.id end = o.id;
</code></pre></div><h3 id="mapjoin"><a href="#mapjoin" aria-hidden="true" class="header-anchor">#</a> MapJoin</h3> <p>​    如果不指定MapJoin或者不符合MapJoin的条件，那么Hive解析器会将Join操作转换成Common Join，即在Reduce阶段完成Join。容易发生数据倾斜。可以用MapJoin把小表全部加载到内存map端进行Join，避免reducer处理。</p> <p>1.开启MapJoin参数设置</p> <p>​    1.设置自动选择MapJoin（默认为true）</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.auto.convert.join = true;
</code></pre></div><p>​        2.大表小表的值域设置（默认25M以下认为是小表）</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.mapjoin.smalltable.filesize=25000000
</code></pre></div><p><img src="/Users/june/program/note/%E5%A4%A7%E6%95%B0%E6%8D%AE/images/70-20190704143856861.png" alt="img"></p> <h3 id="group-by"><a href="#group-by" aria-hidden="true" class="header-anchor">#</a> Group By</h3> <p>​    默认情况下，Map阶段同一key数据分发给一个reduce，当一个key数据过大时就倾斜了。并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作可以先在map端进行部分聚合，最后在Reduce端得出最终结果。</p> <p>1.是否在Map端进行聚合（默认为True）</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.map.aggr = true
</code></pre></div><p>2.在Map端进行聚合操作的条目数目</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.groupby.mapaggr.checkinterval = 100000
</code></pre></div><p>3.数据倾斜的时候进行负载均衡（默认是false）</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.groupby.skewindata = true
</code></pre></div><p>​        当选项设定为true，生成的查询计划会有两个MRjob。第一个job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果。这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个Job在根据预处理的数据结果按照Group By Key分不到Reduce中，最后完成最终的聚合操作。</p> <h3 id="数据倾斜优化"><a href="#数据倾斜优化" aria-hidden="true" class="header-anchor">#</a> 数据倾斜优化</h3> <h4 id="合理设置map数量"><a href="#合理设置map数量" aria-hidden="true" class="header-anchor">#</a> 合理设置Map数量</h4> <p>1、通常情况下，作业会通过input的目录产生一个或者多个map任务</p> <p>主要的决定因素有：input的文件总个数，input的文件大小，集群设置的文件块大小。</p> <p>2、Map并非越多越好</p> <p>如果一个任务有很多小文件，则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成最大的资源浪费。而且，同时可执行的map数是受限制的。</p> <p>3、保证每个map处理接近128m的文件快，就没有问题吗？</p> <p>有个一个127m的文件，默认情况下会用一个map去完成，但这个文件只有一个或者两个小字段，却有着几千万行记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。</p> <h4 id="小文件进行合并"><a href="#小文件进行合并" aria-hidden="true" class="header-anchor">#</a> 小文件进行合并</h4> <p>在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.input.format = org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
</code></pre></div><h4 id="复杂文件增加map数"><a href="#复杂文件增加map数" aria-hidden="true" class="header-anchor">#</a> 复杂文件增加Map数</h4> <p>​    当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</p> <p>​    增加map的方法为：根据computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=128M公式，调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。</p> <div class="language- extra-class"><pre class="language-text"><code>set mapreduce.input.fileinputformat.split.maxsize = 100;
</code></pre></div><h4 id="合理设置reduce数"><a href="#合理设置reduce数" aria-hidden="true" class="header-anchor">#</a> 合理设置Reduce数</h4> <p>1、调整reduce个数方法</p> <p>（1）每个Reduce处理的数据量默认是256MB</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.exec.reducers.bytes.per.reducer = 256000000
</code></pre></div><p>（2）每个任务最大的reduce数，默认为1009</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.exec.reducers.max = 1009
</code></pre></div><p>（3）计算reducer数的公式</p> <p>​            N=min（参数2，总输入数据量/参数1）</p> <p>2、调整reduce个数方法</p> <p>​        在hadoop的mapred-default.xml文件中修改，设置每个job的Reduce个数</p> <div class="language- extra-class"><pre class="language-text"><code>set mapreduce.job.reduces = 15;
</code></pre></div><p>3、.reduce个数并不是越多越好</p> <p>（1）过多的启动和初始化reduce也会消耗时间和资源；</p> <p>（2）另外，有多少个reduce，就会有多少个输出文件，如果产生了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</p> <p>​    在设置reduce个数的时候也需要考虑这两个原则：处理大数据利用适合的reduce数；使单个reduce任务处理数据大小要合适；</p> <h3 id="并行执行"><a href="#并行执行" aria-hidden="true" class="header-anchor">#</a> 并行执行</h3> <p>​    Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过某个特定的job可以包含众多的阶段，而这些阶段可能并非完全相互依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。</p> <p>​    通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p> <p>打开任务并行执行</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.exec.parallel = true;
</code></pre></div><p>同一个sql允许最大并行度，默认为8</p> <div class="language- extra-class"><pre class="language-text"><code>set hive.exec.parallel.thread.number = 16;
</code></pre></div><h3 id="严格模式"><a href="#严格模式" aria-hidden="true" class="header-anchor">#</a> 严格模式</h3> <p>​    hive提供了一个严格模式，可以方式用户执行那些可能意识不到的不好的影响的查询。</p> <p>​    通过设置属性hive.mapred.mode默认值是非严格模式（nonstrict）。开启严格模式需要修改hive.mapred.mode值为strict，开启严格模式可以禁止3种类型的查询。</p> <div class="language- extra-class"><pre class="language-text"><code>&lt;property&gt;
    &lt;name&gt;hive.mapred.mode&lt;/name&gt;
    &lt;value&gt;strict&lt;/value&gt;
&lt;/property&gt;
</code></pre></div><p>1.对于分区表，除非where语句中含有分区字段过滤条件来限制使用范围，否则不允许执行。就是用户不允许扫描所有的分区。进行这个限制的原因是，通常分区表都拥有非常庞大的数据集，而且数据迅速增加。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</p> <p>2.对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reduce中进行处理，强制要求用户增加这个limit语句可以防止Reduce额外执行很长一段时间。</p> <p>3.限制笛卡尔积的查询。对关系数据库非常了解的时候可能在执行Join查询的时候不使用on语句而是用where语句，这样关系数据库的执行优化器就可以高效的将Where语句转换成on语句，但是Hive并不会执行这种优化，因此，如果该表很大，这个查询就会出现不可控的情况。</p> <h3 id="jvm重用"><a href="#jvm重用" aria-hidden="true" class="header-anchor">#</a> JVM重用</h3> <p>​    JVM重用是Hadoop调优参数的内容，其对hive的性能具有非常大的影响，特别是对于很难避免的小文件的场景或task特别多的场景，这类场景大多数执行时间都很短。</p> <p>​    Hadoop的默认配置通常是使用派生JVM来执行map和Reduce任务的。这时JVM的启动过程可能会造成相当大的开销，尤其是执行的job包含成百上千task任务的情况。JVM重用可以使得JVM实例在同一个job中重新使用N次。N的值可以在Hadoop的mapred-site.xml文件中进行配置。通常在10-20之间，具体多少需要根据具体业务场景测试得出。</p> <div class="language- extra-class"><pre class="language-text"><code>&lt;property&gt;
    &lt;name&gt;mapreduce.job.jvm.numtasks&lt;/name&gt;
    &lt;value&gt;10&lt;/vaule&gt;
&lt;/property&gt;
</code></pre></div><p>​        这个功能的缺点是，开启jvm重启将会一直占用使用到的task插槽，以便使用重启，知道任务完成后才会释放。如果某个“不平衡的”job中有几个reduce task时间要比其他的reduce task消耗的时间多很多的话，那么保留的插槽将会一直空闲着缺无法被其他的job使用，直到所有的task都结束了才会释放。</p> <h3 id="查看语句执行计划"><a href="#查看语句执行计划" aria-hidden="true" class="header-anchor">#</a> 查看语句执行计划</h3> <p>通过查看语句的执行计划单独对语句进行优化</p> <p>基本语法：EXPLAIN [EXTENDED|DEPENDENCY|AUTHORIZATION] qurey</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/wiki/hadoop/hadoop-5-Yarn.html" class="prev">
          Yarn
        </a></span> <span class="next"><a href="/wiki/hadoop/hadoop-7-Kafka.html">
          Kafka
        </a>
        →
      </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/wiki/assets/js/app.dd178f5a.js" defer></script><script src="/wiki/assets/js/2.9f273a62.js" defer></script><script src="/wiki/assets/js/25.306828f5.js" defer></script>
  </body>
</html>
